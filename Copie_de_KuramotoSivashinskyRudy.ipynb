{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de KuramotoSivashinskyRudy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvnhcmus/1M-agents-RL/blob/master/Copie_de_KuramotoSivashinskyRudy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv4AqeHbRS-F",
        "colab_type": "text"
      },
      "source": [
        "This notebook demonstrates our approach on the Kuramoto Sivashinsky equation using the dataset from Rudy et al\n",
        "$$\n",
        "u_t + u_{xxxx} + uu_{x}+u_{xx} = 0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxE3iM8eRZmc",
        "colab_type": "text"
      },
      "source": [
        "# Kuramoto Sivashinsky Equation\n",
        "$u_t = -u_{xxxx} - uu_{x}-u_{xx}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZs1-3xJSg53",
        "colab_type": "code",
        "outputId": "350421e5-6238-49d1-ccd5-9c5ace407b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%pylab inline\n",
        "pylab.rcParams['figure.figsize'] = (9, 6)\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn import linear_model\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlYsgTUWS1Jw",
        "colab_type": "text"
      },
      "source": [
        "# Importing data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WyhLZTrUbch",
        "colab_type": "code",
        "outputId": "9d77e229-1eba-4005-ad35-a0fe1f14c1a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "# raw=true is important so you download the file rather than the webpage.\n",
        "!wget https://github.com/snagcliffs/PDE-FIND/blob/master/Datasets/kuramoto_sivishinky.mat?raw=true\n",
        "# rename the file\n",
        "!mv kuramoto_sivishinky.mat\\?raw\\=true kuramoto_sivishinky.mat\n",
        "data = sio.loadmat('kuramoto_sivishinky.mat')\n",
        "u = np.real(data['uu'])\n",
        "x = np.real(data['x'][:,0])\n",
        "t = np.real(data['tt'][0,:])\n",
        "(n,m)=u.shape\n",
        "Xmesh,Tmesh = np.meshgrid(x,t)\n",
        "Xmesh = Xmesh.T\n",
        "Tmesh = Tmesh.T\n",
        "umesh = u\n",
        "# flatten the data to put into the network\n",
        "X = np.transpose((Xmesh.flatten(), Tmesh.flatten()))\n",
        "y = np.real(u.flatten()).reshape(n*m,1)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-30 07:19:00--  https://github.com/snagcliffs/PDE-FIND/blob/master/Datasets/kuramoto_sivishinky.mat?raw=true\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/snagcliffs/PDE-FIND/raw/master/Datasets/kuramoto_sivishinky.mat [following]\n",
            "--2020-03-30 07:19:00--  https://github.com/snagcliffs/PDE-FIND/raw/master/Datasets/kuramoto_sivishinky.mat\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/snagcliffs/PDE-FIND/master/Datasets/kuramoto_sivishinky.mat [following]\n",
            "--2020-03-30 07:19:00--  https://raw.githubusercontent.com/snagcliffs/PDE-FIND/master/Datasets/kuramoto_sivishinky.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1589304 (1.5M) [application/octet-stream]\n",
            "Saving to: ‘kuramoto_sivishinky.mat?raw=true’\n",
            "\n",
            "kuramoto_sivishinky 100%[===================>]   1.52M  7.29MB/s    in 0.2s    \n",
            "\n",
            "2020-03-30 07:19:01 (7.29 MB/s) - ‘kuramoto_sivishinky.mat?raw=true’ saved [1589304/1589304]\n",
            "\n",
            "(257024, 2) (257024, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2d1B3O6clke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To add noise\n",
        "noise_level = 0\n",
        "y_noisy = y + noise_level * np.std(y) * np.random.randn(y.size, 1)\n",
        "# To take a sample of size 20000 for our study\n",
        "number_of_samples = 10000\n",
        "np.random.seed(123)\n",
        "idx = np.random.permutation(y.size)\n",
        "X_train = X[idx, :][:number_of_samples]\n",
        "X_train2 = X[idx, :][:number_of_samples] # notes\n",
        "y_train = y_noisy[idx, :][:number_of_samples]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68MvBAf0Lx_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcNorm(vector):\n",
        "    if (vector.dtype == np.float16):\n",
        "        vector = vector.astype(np.float32)\n",
        "    return np.linalg.norm(vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAHC2lTikP5N",
        "colab_type": "text"
      },
      "source": [
        "# Define a function to calculate derivatives using automatic differentiations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH1762-fkQUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_deriv(X_train):\n",
        "    u = y_train.flatten()\n",
        "    first_col = tf.constant(np.repeat(1.0,len(u)))\n",
        "    X_traintf = tf.constant(X_train)\n",
        "    with tf.GradientTape() as g:\n",
        "        g.watch(X_traintf)\n",
        "        with tf.GradientTape() as g1:\n",
        "            g1.watch(X_traintf)\n",
        "            with tf.GradientTape() as g2:\n",
        "                g2.watch(X_traintf)\n",
        "                with tf.GradientTape() as g3:\n",
        "                    g3.watch(X_traintf)\n",
        "                    with tf.GradientTape(persistent=True) as g4:\n",
        "                        g4.watch(X_traintf)\n",
        "                        res = model.call(X_traintf)\n",
        "                    deri1 = g4.gradient(res,X_traintf)   # 1st order derivatives\n",
        "                    \n",
        "                    # print(deri1.shape)\n",
        "                    # print(deri1[:,:,:,:,0])\n",
        "                    # print(deri1[:,:,:,:,1])\n",
        "\n",
        "                    # u_x, u_t = deri1[:,0],deri1[:,1]\n",
        "                    u_x, u_t = deri1[:,:,:,:,0],deri1[:,:,:,:,1]\n",
        "                    del g4  \n",
        "                    # print(deri1[:,1])\n",
        "\n",
        "                print('--------------')  \n",
        "                deri2a = g3.gradient(u_x,X_traintf)\n",
        "                print(deri2a.shape)\n",
        "                u_xx = deri2a[:,0]\n",
        "                # print(\"------------\")\n",
        "                print(u_xx)\n",
        "            deri3a = g2.gradient(u_xx,X_traintf)\n",
        "            u_xxx = deri3a[:,0] \n",
        "        deri4a = g1.gradient(u_xxx,X_traintf)\n",
        "        u_xxxx = deri4a[:,0] \n",
        "    deri5a = g.gradient(u_xxxx,X_traintf)\n",
        "    u_xxxxx  = deri5a[:,0]   \n",
        "    res = tf.cast(tf.keras.backend.flatten(res),tf.float64)\n",
        "    Theta = tf.stack((first_col,u_x,u_xx, u_xxx,u_xxxx,u_xxxxx,\n",
        "                      res, res*u_x, res*u_xx,res*u_xxx,res*u_xxxx,res*u_xxxxx,\n",
        "                      res**2, res**2*u_x, res**2*u_xx, res**2*u_xxx,res**2*u_xxxx,res**2*u_xxxxx,),axis=1)\n",
        "    return Theta, u_t, res # res = model.call(X_traintf)\n",
        "deri_dict = {0:'1', 1: 'u_x', 2: 'u_xx', 3: 'u_xxx',4: 'u_xxxx',5: 'u_xxxxx',\n",
        "             6: 'u', 7: 'uu_x', 8: 'uu_xx',9: 'uu_xxx',10: 'uu_xxxx',11: 'uu_xxxxx',\n",
        "             12: 'u^2', 13: 'u^2u_x', 14: 'u^2u_xx', 15:'u^2u_xxx', 16:'u^2u_xxxx', 17:'u^2u_xxxxx'}\n",
        "\n",
        "\n",
        "\n",
        "# testing\n",
        "# print(X_train.shape)\n",
        "\n",
        "# df = cal_deriv(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxyGNsD4kg4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel,self).__init__(name = 'my_model')\n",
        "        self.dense_1 = layers.ConvLSTM2D(filters = 64, kernel_size =(1,1),\n",
        "                                        activation = 'relu',\n",
        "                                        input_shape = (1,1,1,2))\n",
        "        self.flat = layers.Flatten()\n",
        "        self.rep  = layers.RepeatVector(3)\n",
        "        self.dense_2 = layers.LSTM(50)\n",
        "        self.dense_3 = layers.LSTM(50)\n",
        "        self.dense_4 = layers.LSTM(50)\n",
        "        self.dense_5 = layers.LSTM(50)\n",
        "        self.dense_6 = layers.LSTM(50)\n",
        "        self.dense_7 = layers.LSTM(50)\n",
        "        #self.batn_1 = layers.BatchNormalization()\n",
        "        self.dense_8 = layers.Dense(1)\n",
        "    def call(self, inputs):\n",
        "        # Define your forward pass here\n",
        "        x = self.dense_1(inputs)\n",
        "        x = self.flat(x)\n",
        "        x = self.rep(x)\n",
        "        x = self.dense_2(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.rep(x)\n",
        "        x = self.dense_3(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.rep(x)\n",
        "        x = self.dense_4(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.rep(x)\n",
        "        x = self.dense_5(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.rep(x)\n",
        "        x = self.dense_6(x)\n",
        "        x = self.flat(x)\n",
        "        x = self.rep(x)\n",
        "        x = self.dense_7(x)\n",
        "        return self.dense_8(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8GXhTVpkn6G",
        "colab_type": "code",
        "outputId": "62ed99f2-ee9d-4d1f-8206-afbb6da2e003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "# reshape into subsequences [samples, time steps, rows, cols, channels]\n",
        "X_train = X_train.reshape((-1,1,1,1,2))\n",
        "# reshape output into [samples, timesteps, features]\n",
        "y_train = y_train.reshape((-1,1,1))\n",
        "model = MyModel()\n",
        "optimizer = tf.keras.optimizers.Adam(0.002)\n",
        "model.compile(loss='mse',\n",
        "                    optimizer=optimizer)#,\n",
        "                    #metrics=['mae', 'mse'])\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size = 1000)#, \n",
        "                    #validation_split = 0.2, verbose=0)\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "norm_val = calcNorm(y_pred-y_train)\n",
        "norm_val2 = calcNorm(y_train)\n",
        "print(\"relative L2 error on train set is {}\".format(norm_val/norm_val2))\n",
        "#print('relative L2 error on train set:',np.linalg.norm(y_pred-y_train,2)/np.linalg.norm(y_train,2))\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10/10 [==============================] - 1s 86ms/step - loss: 1.1082\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 1.0362\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 1s 146ms/step - loss: 0.9972\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 2s 233ms/step - loss: 0.9769\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 2s 208ms/step - loss: 0.9633\n",
            "relative L2 error on train set is 106.87023086420035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.108198</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.036230</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.997233</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.976879</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.963279</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  epoch\n",
              "0  1.108198      0\n",
              "1  1.036230      1\n",
              "2  0.997233      2\n",
              "3  0.976879      3\n",
              "4  0.963279      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWCLShY6liDi",
        "colab_type": "text"
      },
      "source": [
        "Take a sample of 2000 data points. First, we predict u (denoise) and again, check the performance of the NN before proceeding to the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K61MvWCli0r",
        "colab_type": "code",
        "outputId": "e0c7f849-14c4-4972-df08-9208526274e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "np.random.seed(321)\n",
        "idtest = np.random.permutation(y.size)\n",
        "print(X_train.shape)\n",
        "\n",
        "X_test = X[idtest, :][:number_of_samples]\n",
        "y_test = y_noisy[idtest, :][:number_of_samples]\n",
        "\n",
        "print(X_test.shape)\n",
        "\n",
        "y_pred = model.predict(X_train)\n",
        "print('MSE:', np.mean(np.square(y_train-y_pred)))\n",
        "print('relative L2 error on train set:',np.linalg.norm(y_pred-y_train)/np.linalg.norm(y_train))\n",
        "\n",
        "X_test = X_test.reshape((-1,1,1,1,2))\n",
        "print(X_test.shape)\n",
        "\n",
        "yhat = model.predict(X_test)\n",
        "print('MSE:', np.mean(np.square(y_test-yhat)))\n",
        "print('relative L2 error on test set:',np.linalg.norm(yhat-y_test)/np.linalg.norm(y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 1, 1, 1, 2)\n",
            "(10000, 2)\n",
            "MSE: 1.2699906225761433\n",
            "relative L2 error on train set: 106.87023086420035\n",
            "(10000, 1, 1, 1, 2)\n",
            "MSE: 0.9415156699443347\n",
            "relative L2 error on test set: 0.9224370435806797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaRVBdJEluvp",
        "colab_type": "text"
      },
      "source": [
        "The performance is good. We will now calculate the derivatives using automatic differentiations using the function cal_deriv defined above and construct the function library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff6S4ws7lzD7",
        "colab_type": "text"
      },
      "source": [
        "**Example (KdV equation)**\n",
        "\n",
        "True model:\n",
        "\n",
        "$u_t = -6uu_x - u_{xxx}$\n",
        "\n",
        "Library of potential terms:\n",
        "\n",
        "deri_dict = $('1','u','u^2','u^3', 'u^4','u^5','u_{x}','uu_{x}','u^2u_{x}','u^3u_{x}','u^4u_{x}','u^5u_{x}','u_{xx}',\n",
        "'uu_{xx}','u^2u_{xx}','u^3u_{xx}', 'u^4u_{xx}', 'u^5u_{xx}', 'u_{xxx}', 'uu_{xxx}', 'u^2u_{xxx}', 'u^3u_{xxx}', 'u^4u_{xxx}', 'u^5u_{xxx}', 'u_{xxxx}', 'uu_{xxxx}', 'u^2u_{xxxx}','u^3u_{xxxx}', 'u^4u_{xxxx}', 'u^5u_{xxxx}', 'u_{xxxxx}', 'uu_{xxxxx}', 'u^2u_{xxxxx}','u^3u_{xxxxx}', 'u^4u_{xxxxx}','u^5u_{xxxxx}')$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBYUW8y6lvNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "5dcbab79-c747-4d29-d863-07a987c77c4a"
      },
      "source": [
        "# reshape into subsequences [samples, time steps, rows, cols, channels]\n",
        "print(X_train.shape)\n",
        "\n",
        "df = cal_deriv(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 1, 1, 1, 2)\n",
            "WARNING:tensorflow:Layer conv_lst_m2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "--------------\n",
            "(10000, 1, 1, 1, 2)\n",
            "tf.Tensor(\n",
            "[[[[ 1.60986721e-03  2.96389102e-04]]]\n",
            "\n",
            "\n",
            " [[[-1.13157395e-04  1.96322420e-04]]]\n",
            "\n",
            "\n",
            " [[[-1.34400427e-04 -5.13412378e-05]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-3.35243385e-07 -3.06692498e-04]]]\n",
            "\n",
            "\n",
            " [[[-5.63052949e-04 -6.34680619e-04]]]\n",
            "\n",
            "\n",
            " [[[ 5.48012741e-03 -1.60495995e-03]]]], shape=(10000, 1, 1, 2), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNIpMrG8n-X4",
        "colab_type": "text"
      },
      "source": [
        "# Coefficients Estimation using AIC/BIC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNw5szxLn_Gx",
        "colab_type": "code",
        "outputId": "42e5344f-54bd-4894-fa4d-3a9d72c1ab3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC\n",
        "import time \n",
        "Theta, u_t,res = cal_deriv(X_train)\n",
        "Theta, u_t = Theta.numpy(), u_t.numpy()\n",
        "\n",
        "EPSILON = 1e-10\n",
        "model_bic = LassoLarsIC(criterion='bic')\n",
        "t1 = time.time()\n",
        "model_bic.fit(Theta, u_t)\n",
        "t_bic = time.time() - t1\n",
        "alpha_bic_ = model_bic.alpha_\n",
        "print(model_bic.coef_)\n",
        "\n",
        "model_aic = LassoLarsIC(criterion='aic')\n",
        "model_aic.fit(Theta, u_t)\n",
        "alpha_aic_ = model_aic.alpha_\n",
        "print(model_aic.coef_)\n",
        "\n",
        "def plot_ic_criterion(model, name, color):\n",
        "    alpha_ = model.alpha_ + EPSILON\n",
        "    alphas_ = model.alphas_ + EPSILON\n",
        "    criterion_ = model.criterion_\n",
        "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n",
        "             linewidth=3, label='%s criterion' % name)\n",
        "    plt.axvline(-np.log10(alpha_), color=color, linewidth=3,\n",
        "                label='alpha: %s estimate' % name)\n",
        "    plt.xlabel('-log(alpha)')\n",
        "    plt.ylabel('criterion')\n",
        "\n",
        "plt.figure()\n",
        "plot_ic_criterion(model_aic, 'AIC', 'b')\n",
        "plot_ic_criterion(model_bic, 'BIC', 'r')\n",
        "plt.legend()\n",
        "plt.title('Information-criterion for model selection (training time %.3fs)'\n",
        "          % t_bic)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-779f89f66c58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLassoCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLassoLarsCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLassoLarsIC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcal_deriv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mTheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-4883c1bc95b6>\u001b[0m in \u001b[0;36mcal_deriv\u001b[0;34m(X_train)\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_traintf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mderi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_traintf\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 1st order derivatives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     \u001b[0mu_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderi1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mderi1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                     \u001b[0;32mdel\u001b[0m \u001b[0mg4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mderi2a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_traintf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1148\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10155\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10156\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10157\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10158\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10159\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbegin_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: slice index 1 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k_1dkZ8oIBA",
        "colab_type": "code",
        "outputId": "6490b575-00e7-4ec9-cac0-2c290edae5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "xi = model_bic.coef_ \n",
        "coef_tol = 1e-5           \n",
        "remaining = np.arange(len(deri_dict))[(np.absolute(xi)>coef_tol)]\n",
        "num_terms = len(remaining)\n",
        "non0 = np.array(np.where(np.arange(len(deri_dict))*np.absolute(xi).flatten()>coef_tol)).flatten()\n",
        "xi = xi[remaining]\n",
        "l = non0.tolist()\n",
        "def non0_deri_dict(non0):\n",
        "  my_dict = {}\n",
        "  for i in non0:\n",
        "    my_dict[i]=deri_dict[i]\n",
        "  return my_dict\n",
        "w2 = non0_deri_dict(non0)\n",
        "print(w2,'\\n', xi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 'u_x', 2: 'u_xx', 3: 'u_xxx', 4: 'u_xxxx', 6: 'u', 7: 'uu_x', 8: 'uu_xx', 12: 'u^2', 13: 'u^2u_x'} \n",
            " [-2.53414778e-02  6.17520564e-03  2.11550423e-03  2.86263154e-05\n",
            "  8.69426946e-03 -7.76886656e-02 -2.89931985e-03 -1.83433182e-03\n",
            " -1.14370672e-02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2scdoEyaoNo2",
        "colab_type": "text"
      },
      "source": [
        "Drop small coefficients and perform linear regression on remaining coefficients. Those small coefficients are officially dropped if the difference in Loss MSE is smaller than a tol."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1_Tr-2kuCSy",
        "colab_type": "text"
      },
      "source": [
        "# Backward Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9-C4fmOuD5O",
        "colab_type": "code",
        "outputId": "dc7a4310-5e08-4004-d546-7918906e6ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# To take a sample of size 5000 to validate \n",
        "np.random.seed(321)\n",
        "idx = np.random.permutation(y.size)\n",
        "X_valid = X[idx, :][:number_of_samples]\n",
        "y_valid = y_noisy[idx, :][:number_of_samples]\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "Theta_valid, ut_valid,_ = cal_deriv(X_valid)\n",
        "Theta_valid, ut_valid = Theta_valid.numpy(), ut_valid.numpy()\n",
        "\n",
        "def mse_backward_selection(non0, mse_rm_thres = 1e-4):\n",
        "    for i in non0:\n",
        "        reg_full = LinearRegression().fit(Theta_valid[:,non0], ut_valid)\n",
        "        reg_reduced = LinearRegression().fit(\n",
        "            Theta_valid[:,np.setdiff1d(non0, [i])], ut_valid)\n",
        "        ful_valid_mse = np.mean(np.square(\n",
        "            reg_full.predict(Theta_valid[:,non0])-ut_valid))\n",
        "        redu_valid_mse = np.mean(np.square(reg_reduced.predict(\n",
        "            Theta_valid[:,np.setdiff1d(non0, [i])])-ut_valid))\n",
        "        if (redu_valid_mse - ful_valid_mse<mse_rm_thres):\n",
        "            print(redu_valid_mse - ful_valid_mse)\n",
        "            non0 = np.setdiff1d(non0, [i]) \n",
        "    return non0 \n",
        "selected_id = mse_backward_selection(non0)\n",
        "print(selected_id)\n",
        "coef = LinearRegression().fit(Theta[:,selected_id], u_t).coef_\n",
        "print(coef)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.570510229836509e-05\n",
            "2.8150740483456893e-05\n",
            "1.2391787549526079e-05\n",
            "5.277155715951998e-06\n",
            "4.336932474396926e-07\n",
            "4.4827587522319745e-05\n",
            "[1 3 7]\n",
            "[-0.04331184  0.00170577 -0.07648857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JAq9BXid_Q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}